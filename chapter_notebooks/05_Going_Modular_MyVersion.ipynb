{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJDdBJCv3FBEYQBGEkConW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bbe6b9ca902c487cba0c3a46277b62fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27187a3c5b094dc7a610d4f6f01f6af1","IPY_MODEL_57cc0ce393f34b00980a8f08d2e3523c","IPY_MODEL_af77b9edf4e24fd1aa3565fc9a115341"],"layout":"IPY_MODEL_9e800f7e7e9a403cad95da5336774a5c"}},"27187a3c5b094dc7a610d4f6f01f6af1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d476a43e3d5a44dcad96b7c79027b917","placeholder":"​","style":"IPY_MODEL_c759baaab4974f14a34a69243b72a2c7","value":"100%"}},"57cc0ce393f34b00980a8f08d2e3523c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ad4292d0ec40b7a2649cdd643526d3","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73c8d79281af4ca5a7af20734d2edf95","value":100}},"af77b9edf4e24fd1aa3565fc9a115341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f00ad46f5e54a78b98dbd288725f4a1","placeholder":"​","style":"IPY_MODEL_ecdef1bc204847b18bcd799837eab384","value":" 100/100 [03:35&lt;00:00,  2.05s/it]"}},"9e800f7e7e9a403cad95da5336774a5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d476a43e3d5a44dcad96b7c79027b917":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c759baaab4974f14a34a69243b72a2c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03ad4292d0ec40b7a2649cdd643526d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73c8d79281af4ca5a7af20734d2edf95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f00ad46f5e54a78b98dbd288725f4a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecdef1bc204847b18bcd799837eab384":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 1. Importing Data"],"metadata":{"id":"zhHJKB4n2QCt"}},{"cell_type":"code","source":["import os\n","import requests\n","import zipfile\n","from pathlib import Path\n","\n","# Create Image Directory\n","DATA_PATH = Path(\"data/\")\n","IMAGE_PATH = DATA_PATH / \"pizza_steak_sushi\"\n","\n","if IMAGE_PATH.is_dir():\n","  print(f\"Directory {IMAGE_PATH} already exists\")\n","else:\n","  print(f\"Creating directory {IMAGE_PATH} ...\")\n","  IMAGE_PATH.mkdir(parents=True, exist_ok=True)\n","\n","# Import the data zipfile from GitHub\n","github_url = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\n","with open(DATA_PATH / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","  request = requests.get(github_url)\n","  print(f\"Fetching Image Data Zip File ...\")\n","  f.write(request.content)\n","\n","\n","# Open zip file\n","with zipfile.ZipFile(DATA_PATH / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","  print(\"Opening Zip File ...\")\n","  zip_ref.extractall(IMAGE_PATH)\n","  print(\"Zip file succesfully opened\")\n","\n","os.remove(DATA_PATH / \"pizza_steak_sushi.zip\")"],"metadata":{"id":"h-tnqjaz2W5f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725355102459,"user_tz":-60,"elapsed":2456,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"15116e58-89e8-4944-f31b-a49c80e0707b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating directory data/pizza_steak_sushi ...\n","Fetching Image Data Zip File ...\n","Opening Zip File ...\n","Zip file succesfully opened\n"]}]},{"cell_type":"markdown","source":["# 2. Creating Python Modules for Model Training"],"metadata":{"id":"Z_AyYrtqLvW3"}},{"cell_type":"code","source":["## Creating Parent Directory for Modular Verision of Python Model\n","import os\n","os.makedirs(\"modular_pytorch\", exist_ok=True)"],"metadata":{"id":"A25k1zonSUXL","executionInfo":{"status":"ok","timestamp":1725355102459,"user_tz":-60,"elapsed":2,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Create dataloader creation function and add it to 'modular_pytorch/data_setup.py'\n","%%writefile modular_pytorch/data_setup.py\n","\"\"\"\n","This file contains the functionality for creating PyTorch DataLoaders for\n","image classification data.\n","\"\"\"\n","\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","def create_dataloaders(train_dir : str, test_dir : str,\n","                       train_transform : transforms.Compose, test_transform : transforms.Compose,\n","                       batch_size : int, num_workers : int):\n","  \"\"\"\n","  This function creates dataloaders for training and evaluating a pytorch model\n","\n","  ------------------------------------------------------------------------------\n","  Inputs:\n","\n","  train_dir - The path of the diredctory containing the training image data\n","  test_dir - The path of the directory containing the testing image data\n","  train_transform - The transformation we want to apply to the training image data\n","  test_transform - The transformation we want to apply to the testing image data\n","  batch_size - The size of the mini-batches in the dataloaders\n","  num_workers - The number of workers assigned to create the dataloaders\n","\n","  ------------------------------------------------------------------------------\n","  Outputs:\n","\n","  train_dataloader - the training dataloader (with shuffling applied)\n","  test_dataloader - the testing dataloader\n","  class_names - the names of the different classes in the training & testing data\n","  \"\"\"\n","\n","  # Create training & testing datasets using `ImageFolder` function\n","  train_data = datasets.ImageFolder(train_dir,\n","                                    transform=train_transform,\n","                                    target_transform=None)\n","\n","  test_data = datasets.ImageFolder(test_dir,\n","                                   transform=test_transform)\n","\n","  # Get class names\n","  class_names = train_data.classes\n","\n","  # Create training & testing dataloaders\n","  train_dataloader = DataLoader(train_data,\n","                                batch_size=batch_size,\n","                                shuffle=True,\n","                                num_workers=num_workers)\n","\n","  test_dataloader = DataLoader(test_data,\n","                               batch_size=batch_size,\n","                               shuffle=False,\n","                               num_workers = num_workers)\n","\n","  return train_dataloader, test_dataloader, class_names"],"metadata":{"id":"p8yd-OA9SUwZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725355102459,"user_tz":-60,"elapsed":2,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"22c2c358-c717-49c6-8e68-414e00426df6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing modular_pytorch/data_setup.py\n"]}]},{"cell_type":"code","source":["## Create TinyVGG model class & add it to model_builder.py script\n","%%writefile modular_pytorch/model_builder.py\n","\"\"\"\n","This file contains the TinyVGG model class\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","\n","class TinyVGG(nn.Module):\n","  \"\"\"\n","  Creates the TinyVGG CNN architecture\n","\n","  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","\n","  ---------------------------------------------------------\n","  Args:\n","\n","  input_shape - the number of input channels\n","  output_shape - the number of output channels\n","  hidden_channels - the number of channels in the hidden layers\n","\n","  \"\"\"\n","\n","  def __init__(self, input_shape : int, output_shape : int, hidden_channels : int=10):\n","    super().__init__()\n","\n","    self.conv_layer1 = nn.Sequential(\n","                                    nn.Conv2d(in_channels=input_shape, out_channels=hidden_channels,\n","                                              kernel_size=3, stride=1, padding=0),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                                              kernel_size=3, stride=1, padding=0),\n","                                    nn.ReLU(),\n","                                    nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n","                                    )\n","\n","    self.conv_layer2 = nn.Sequential(\n","                                    nn.Conv2d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                                              kernel_size=3, stride=1, padding=0),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                                              kernel_size=3, stride=1, padding=0),\n","                                    nn.ReLU(),\n","                                    nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n","                                    )\n","\n","    self.classifier_layer = nn.Sequential(\n","                                          nn.Flatten(),\n","                                          nn.Linear(in_features=hidden_channels*13*13, out_features=output_shape)\n","                                          )\n","\n","  def forward(self, x):\n","    return self.classifier_layer(self.conv_layer2(self.conv_layer1(x)))"],"metadata":{"id":"xVoujZMfSU6I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725355102459,"user_tz":-60,"elapsed":1,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"d0c5760b-1ec0-475f-e0b6-105417376ba8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing modular_pytorch/model_builder.py\n"]}]},{"cell_type":"code","source":["## Create functions for the training and evaluation steps in each epoch, and an overall training function for the entire training process\n","%%writefile modular_pytorch/engine.py\n","\"\"\"\n","Contains functions for model training and evaluation within each epoch, and a function for the overall model training across multiple epochs\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","from torch.utils.data import DataLoader\n","\n","from tqdm.auto import tqdm\n","\n","\n","def train_step(model : nn.Module,\n","               train_dataloader : DataLoader,\n","               device : torch.device,\n","               optimizer : torch.optim,\n","               loss_fn):\n","  \"\"\"\n","  Carries out the training step on a pytorch model & calculates training loss & accuracy\n","\n","  --------------------------------\n","  Inputs:\n","  model - the model to be trained\n","  train_dataloader - the dataloader containing the training data\n","  device - the device on which the model exists\n","  optimizer - the optimizer to use for model training\n","  loss_fn - the loss function used to evaluate the model's success\n","  acc_fn - the accuracy function used to evaluate the model's success\n","\n","\n","  --------------------------------\n","  Outputs: Tuple[loss, acc]\n","  loss - the training loss of the model\n","  acc - the training accuracy of the model\n","  \"\"\"\n","\n","  # Initialize loss & accuracy\n","  train_loss, train_acc = 0, 0\n","\n","  # Set model to training mode\n","  model.train()\n","  for images, labels in train_dataloader:\n","    images, labels = images.to(device), labels.to(device)  # Move batch images & labels to device\n","\n","    y_logits = model(images)   # Carry out forward pass\n","\n","    loss = loss_fn(y_logits, labels)   # Calculate batch loss\n","    train_loss += loss    # Update overall epoch loss\n","\n","    # Calculate and accumulate accuracy metric across all batches\n","    y_pred_class = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n","    train_acc += (y_pred_class == labels).sum().item()/len(y_logits)\n","\n","    # Carry out model training given batch loss\n","    optimizer.zero_grad()  # Zero the optimizer gradient\n","    loss.backward()  # Carry out backpropagation\n","    optimizer.step()  # Update weights\n","\n","\n","  train_loss /= len(train_dataloader)  # Calculate average loss across the dataloader images\n","  train_acc /= len(train_dataloader)   # Calculate average accuracy across the dataloader images\n","\n","  return train_loss, train_acc\n","\n","\n","\n","def eval_step(model : nn.Module,\n","               test_dataloader : DataLoader,\n","               device : torch.device,\n","               loss_fn):\n","  \"\"\"\n","  Carries out the evaluation step on a pytorch model using model.eval() mode with torch.inference_mode() by\n","  calculating the testing loss & accuracy obtained when predicting unseen data classes\n","\n","  --------------------------------\n","  Inputs:\n","  model - the model to be trained\n","  test_dataloader - the dataloader containing the unseen testing data\n","  device - the device on which the model exists\n","  loss_fn - the loss function used to evaluate the model\n","  acc_fn - the accuracy function used to evaluate the model\n","\n","\n","  --------------------------------\n","  Outputs: Tuple[loss, acc]\n","  test_loss - the loss of the model when prediciting the unseen data classes\n","  test_acc - the accuracy of the model in predicting the unseen data classes\n","  \"\"\"\n","\n","  # Initialize loss & accuracy\n","  test_loss, test_acc = 0, 0\n","\n","  # Set model to evaluation mode\n","  model.eval()\n","  with torch.inference_mode():\n","    for images, labels in test_dataloader:\n","        images, labels = images.to(device), labels.to(device)   # Move batch images & labels to device\n","\n","        y_logits = model(images)   # Carry out forward pass\n","\n","        loss = loss_fn(y_logits, labels)   # Calculate batch loss\n","        test_loss += loss.item()    # Update overall epoch loss\n","\n","\n","        test_pred_labels = y_logits.argmax(dim=1)\n","        test_acc += ((test_pred_labels == labels).sum().item()/len(test_pred_labels))\n","\n","    test_loss = test_loss / len(test_dataloader)  # Calculate average loss across the dataloader images\n","    test_acc = test_acc / len(test_dataloader)   # Calculate average accuracy across the dataloader images\n","\n","  return test_loss, test_acc\n","\n","\n","\n","def train_model(model : nn.Module, num_epochs : int,\n","                train_dataloader : DataLoader, test_dataloader : DataLoader,\n","                optimizer : torch.optim,\n","                device : torch.device,\n","                loss_fn):\n","  \"\"\"\n","  Trains the model for a given numebr of epochs & calculates the training and testing loss & accuracy of the model at each epoch in the training process\n","\n","  ------------------------------------------------------------------------\n","  Inputs:\n","  model - model to be trained\n","  num_epochs - the number of epochs for which we want to train the model\n","  train_dataloader - dataloader contatining the training data in batched format\n","  test_dataloader - dataloader containing the testing data in batched format\n","  optimizer - the optimizer to use for model training\n","  device - device on which the model exists & should be trained on\n","  loss_fn - the loss function used to evaluate the model\n","  acc_fn - the accuracy function used to evaluate the model\n","\n","  ------------------------------------------------------------------------\n","  Outputs:\n","  Tuple of lists in the form [train_losses, train_accs, eval_losses, eval_accs]\n","  Each element of the tuple is a list containing the following info:\n","  train_losses - contains the training loss observed at each epoch\n","  eval_losses - contains the testing loss observed at each epoch\n","  train_accs - contains the training accuracies observed at each epoch\n","  eval_losses - contains the testing accuracies observed at each epoch\n","  \"\"\"\n","\n","\n","  # Create lists in which to store model training & evaluation results\n","  train_losses, train_accs = [], []\n","  eval_losses, eval_accs = [], []\n","\n","  for epoch in tqdm(range(num_epochs)):\n","    train_results = train_step(model,\n","                               train_dataloader,\n","                               device, optimizer,\n","                               loss_fn)\n","\n","    eval_results = eval_step(model,\n","                             test_dataloader,\n","                             device,\n","                             loss_fn)\n","\n","    # Print results every 10 epochs\n","    if epoch % 10 == 0:\n","      print(f\"Epoch : {epoch} | Train Loss = {train_results[0]:.4f}, Train Acc = {train_results[1]:2f} | Test Loss = {eval_results[0]:.4f}, Test Acc = {eval_results[1]:.2f}\")\n","\n","    # Append training & evaluation results to lists\n","    train_losses.append(train_results[0])\n","    train_accs.append(train_results[1])\n","\n","    eval_losses.append(eval_results[0])\n","    eval_accs.append(eval_results[1])\n","\n","  return train_losses, train_accs, eval_losses, eval_accs"],"metadata":{"id":"lUew3wBnSVCt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725355102960,"user_tz":-60,"elapsed":502,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"6baefe33-3eff-42a2-daf3-334d9aa46a6f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing modular_pytorch/engine.py\n"]}]},{"cell_type":"markdown","source":["# 3. Training Model Using Modules Created Above"],"metadata":{"id":"-Y0pNvNULzor"}},{"cell_type":"code","source":["try:\n","  import torchvision\n","except:\n","  !pip install torchvision\n","  import torchvision\n","# Create training & testing set dataloaders\n","from modular_pytorch import data_setup\n","\n","BATCH_SIZE = 8\n","NUM_WORKERS = 0\n","standard_transform = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(size=(64,64)),\n","    torchvision.transforms.ToTensor()\n","])\n","\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = \"data/pizza_steak_sushi/train\",\n","                                                                               test_dir = \"data/pizza_steak_sushi/train\",\n","                                                                               train_transform = standard_transform, test_transform = standard_transform,\n","                                                                               batch_size = BATCH_SIZE, num_workers = NUM_WORKERS)"],"metadata":{"id":"o4Mb_h5XSVLF","executionInfo":{"status":"ok","timestamp":1725355116416,"user_tz":-60,"elapsed":13460,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["img, label = next(iter(train_dataloader))"],"metadata":{"id":"rLJysECfO2Q0","executionInfo":{"status":"ok","timestamp":1725355116417,"user_tz":-60,"elapsed":19,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Create instance of Model\n","from modular_pytorch import model_builder\n","model0 = model_builder.TinyVGG(input_shape = 3, output_shape = 3, hidden_channels = 10)"],"metadata":{"id":"71R4IzL7SVS0","executionInfo":{"status":"ok","timestamp":1725355116417,"user_tz":-60,"elapsed":18,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Train model for 100 epochs\n","import torch\n","import torch.nn as nn\n","from modular_pytorch import engine\n","\n","NUM_EPOCHS = 100\n","\n","# Define `model_train` function arguments\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Training model on {device}\")\n","optimizer = torch.optim.SGD(model0.parameters(),\n","                            lr=0.001)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","# Carry out model training\n","train_losses, train_accs, eval_losses, eval_accs = engine.train_model(model = model0, num_epochs = NUM_EPOCHS,\n","                                                                      train_dataloader = train_dataloader, test_dataloader = test_dataloader,\n","                                                                      device = device, optimizer = optimizer,\n","                                                                      loss_fn = loss_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240,"referenced_widgets":["bbe6b9ca902c487cba0c3a46277b62fa","27187a3c5b094dc7a610d4f6f01f6af1","57cc0ce393f34b00980a8f08d2e3523c","af77b9edf4e24fd1aa3565fc9a115341","9e800f7e7e9a403cad95da5336774a5c","d476a43e3d5a44dcad96b7c79027b917","c759baaab4974f14a34a69243b72a2c7","03ad4292d0ec40b7a2649cdd643526d3","73c8d79281af4ca5a7af20734d2edf95","0f00ad46f5e54a78b98dbd288725f4a1","ecdef1bc204847b18bcd799837eab384"]},"id":"UNovlSGePfxf","executionInfo":{"status":"ok","timestamp":1725355332267,"user_tz":-60,"elapsed":215868,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"91b5479f-3ecd-4ca4-b752-7de582fe2da3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Training model on cpu\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe6b9ca902c487cba0c3a46277b62fa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch : 0 | Train Loss = 1.0995, Train Acc = 0.340517 | Test Loss = 1.0993, Test Acc = 0.34\n","Epoch : 10 | Train Loss = 1.0984, Train Acc = 0.362069 | Test Loss = 1.0979, Test Acc = 0.41\n","Epoch : 20 | Train Loss = 1.0964, Train Acc = 0.336207 | Test Loss = 1.0956, Test Acc = 0.34\n","Epoch : 30 | Train Loss = 1.0927, Train Acc = 0.349138 | Test Loss = 1.0921, Test Acc = 0.36\n","Epoch : 40 | Train Loss = 1.0875, Train Acc = 0.405172 | Test Loss = 1.0866, Test Acc = 0.40\n","Epoch : 50 | Train Loss = 1.0777, Train Acc = 0.413793 | Test Loss = 1.0773, Test Acc = 0.42\n","Epoch : 60 | Train Loss = 1.0654, Train Acc = 0.443966 | Test Loss = 1.0623, Test Acc = 0.43\n","Epoch : 70 | Train Loss = 1.0427, Train Acc = 0.456897 | Test Loss = 1.0378, Test Acc = 0.49\n","Epoch : 80 | Train Loss = 1.0008, Train Acc = 0.543103 | Test Loss = 1.0002, Test Acc = 0.51\n","Epoch : 90 | Train Loss = 0.9625, Train Acc = 0.530172 | Test Loss = 0.9511, Test Acc = 0.58\n"]}]},{"cell_type":"markdown","source":["# 4. Creating Modules to Save the Trained Model"],"metadata":{"id":"2W1cZ5svnnkN"}},{"cell_type":"code","source":["### Create utils.py script\n","%%writefile modular_pytorch/utils.py\n","\"\"\"\n","This script contains various utility functions for PyTorch model training & saving\n","\"\"\"\n","import torch\n","from pathlib import Path\n","\n","def save_model(model : nn.Module,\n","               save_dir : str,\n","               model_name : str):\n","  \"\"\"\n","  Saves a PyTorch model to a target directory\n","  --------------------------------------------------------\n","  Inputs:\n","  model - the model to be saved\n","  save_dir - the directory under which we want to save the model\n","  model_name - the name we want to assign to the file containing the saved model (should include '.pth' or '.pt' file extension name)\n","  \"\"\"\n","\n","  # Create saving directory\n","  save_dir_path = Path(save_dir)\n","  save_dir_path.mkdir(parents=True, exist_ok=True)\n","\n","  # Create model save path\n","  assert model_name.endswith('.pth') or model_name.endswith('.pt'), \"model_name should end with '.pth' or '.pt' file extension\"\n","  model_save_path = save_dir_path / model_name\n","\n","  # Save the model's state_dict()\n","  print(f\"[INFO] Saving model to {model_save_path}\")\n","  torch.save(obj=model.state_dict(), f=model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jxud4mlJqRrd","executionInfo":{"status":"ok","timestamp":1725355332267,"user_tz":-60,"elapsed":19,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"6b0d4327-f9c3-4f8c-f019-d7a6dcac1584"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing modular_pytorch/utils.py\n"]}]},{"cell_type":"code","source":["### Create train.py file which carries out entire training, evaluating & saving process\n","%%writefile modular_pytorch/train.py\n","\"\"\"\n","Trains a PyTorch image classification model using device-agnostic code.\n","\"\"\"\n","import os\n","import torch\n","from modular_pytorch import data_setup, model_builder, engine, utils\n","\n","from torchvision import transforms\n","\n","# Setup Hyperparameters\n","NUM_EPOCHS = 100\n","BATCH_SIZE = 8\n","HIDDEN_CHANNELS = 10\n","LEARNING_RATE = 0.001\n","\n","# Setup directories\n","train_dir = 'data/pizza_sushi_steak/train'\n","test_dir = 'data/pizza_sushi_steak/test'\n","\n","# Setup target device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Training Model on {device}\")\n","\n","# Create transforms\n","std_transform = transforms.Compose([\n","    transforms.Resize(size=(64,64)),\n","    transforms.ToTensor()\n","])\n","\n","# Create Dataloaders using data_setup.py module\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir, test_dir = test_dir,\n","                                                                               train_transform = std_transform, test_transform = std_transform,\n","                                                                               batch_size=BATCH_SIZE)\n","\n","# Create TinyVGG model using model_builder.py\n","model = TinyVGG(input_shape=3, output_shape=3, hidden_channels=HIDDEN_CHANNELS).to(device)\n","\n","# Define loss function and optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","\n","\n","# Carry out model training using engine.py\n","train_losses, train_accs, eval_losses, eval_accs = engine.train_model(model=model, num_epochs=NUM_EPOCHS,\n","                                                                      train_dataloader=train_dataloader, test_dataloader=test_dataloader,\n","                                                                      optimizer=optimizer, device=device,\n","                                                                      loss_fn=loss_fn)\n","\n","# Save the model using utils.py\n","utils.save_model(model=model,\n","                 save_dir = 'saved_models/',\n","                 model_name = 'TinyVGG_V1.pth')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swff_lD2sHFJ","executionInfo":{"status":"ok","timestamp":1725355332267,"user_tz":-60,"elapsed":6,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"37142a05-ca2e-4615-8bd2-28f44f89d81d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing modular_pytorch/train.py\n"]}]},{"cell_type":"markdown","source":["# 5. Section 5 'Going Modular' Exercises"],"metadata":{"id":"aq1zN2sNyRvm"}},{"cell_type":"code","source":["# 1. Turn 'Importing Data' Section into a python script\n","\n","# Answer:\n","%%writefile modular_pytorch/get_data.py\n","\"\"\"\n","Import training & testing data from github\n","\"\"\"\n","\n","from pathlib import Path\n","import zipfile\n","import os\n","import requests\n","\n","\n","def import_data(data_dir : str, img_dir : str,\n","                raw_data_url : str,\n","                zipfile_name : str):\n","\n","  # Create dataset directory\n","  data_path = Path(data_dir)\n","  image_path = data_path / img_dir\n","\n","  if data_path.is_dir():\n","    print(f\"Directory {data_path} already exists\")\n","  else:\n","    print(f\"Creating directory {data_path}\")\n","    data_path.mkdir(parents=True, exists_ok=True)\n","\n","  # Import image datasets\n","  assert zipfile_name.endswith('.zip'), \"'zipfile_name' argument must end in '.zip'\"\n","  with open(data_path / zipfile_name, \"wb\") as f:\n","    request = requests.get(raw_data_url)\n","    print(f\"Importing raw data zipfile to {data_path}\")\n","    f.write(request.content)\n","\n","  # Unzip the raw image file\n","  with zipfile.ZipFile(data_path / zipfile_name, \"r\") as zip_ref:\n","    print(f\"Unzipping {data_path / zipfile_name}\")\n","    zip_ref.extractall(image_path)\n","    print(f\"Successfully unzipped data\")\n","\n","  os.remove(data_path / zipfile_name) # Remove zipfile from data directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgV2hW5VyZLV","executionInfo":{"status":"ok","timestamp":1725355332267,"user_tz":-60,"elapsed":5,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}},"outputId":"e7c411a0-9df3-4b94-8cf6-e83e9a88cfce"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing modular_pytorch/get_data.py\n"]}]},{"cell_type":"code","source":["# Testing answer\n","# from modular_pytorch import get_data\n","\n","# get_data.import_data(data_dir = 'data/', img_dir = 'pizza_sushi_steak',\n","#                      raw_data_url = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n","#                      zipfile_name = \"pizza_sushi_steak.zip\")"],"metadata":{"id":"UizkQU8qyZiK","executionInfo":{"status":"ok","timestamp":1725355332267,"user_tz":-60,"elapsed":4,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DPgTUNLsLZL-","executionInfo":{"status":"ok","timestamp":1725355332267,"user_tz":-60,"elapsed":3,"user":{"displayName":"Axel Eichelmann","userId":"01190813789631675972"}}},"execution_count":13,"outputs":[]}]}